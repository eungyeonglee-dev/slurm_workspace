# slurm_workspace
how to write slurm shell for pretraining on multi-GPU training
